{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import gzip\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import inspect\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "# seed = 1337\n",
    "# pickleFile = '../Datasets/Reviews/dataset.pkl'\n",
    "# gloveDimension = 50\n",
    "# glovePath = \"/media/data/Datasets/glove\"\n",
    "# dataset_reduction = 16\n",
    "# trainPortion = 0.80\n",
    "# vocabularyLimit = 30000\n",
    "# cutoff = 60\n",
    "# datasetFile = '../Datasets/Reviews/dataset_ready.pkl'\n",
    "# example_item_id = 19\n",
    "\n",
    "# params = {\n",
    "#     \"seed\" : 1337,\n",
    "#     \"pickleFile\" :  '../Datasets/Reviews/dataset.pkl',\n",
    "#     \"gloveDimension\" : 50,\n",
    "#     \"glovePath\" : \"/media/data/Datasets/glove\",\n",
    "#     \"datasetReduction\" : 16,\n",
    "#     \"trainPortion\" : 0.80,\n",
    "#     \"vocabularyLimit\" : 30000,\n",
    "#     \"cutoff\" : 60,\n",
    "#     \"datasetFile\" : '../Datasets/Reviews/dataset_ready.pkl',\n",
    "#     \"example_item_id\" : 19, \n",
    "#     \"saveDataset\" : False\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    \"seed\" : 1337,\n",
    "    \"pickleFile\" :  '../Datasets/Reviews/dataset.pkl',\n",
    "    \"gloveDimension\" : 50,\n",
    "    \"glovePath\" : \"/media/data/Datasets/glove\",\n",
    "    \"datasetReduction\" : 2048,\n",
    "    \"trainPortion\" : 0.80,\n",
    "    \"vocabularyLimit\" : 10000,\n",
    "    \"cutoff\" : 39,\n",
    "    \"datasetFile\" : '../Datasets/Reviews/dataset_ready.pkl',\n",
    "    \"example_item_id\" : 19, \n",
    "    \"saveDataset\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(params['seed'])\n",
    "np.random.seed(params['seed'])\n",
    "\n",
    "nlp = English()\n",
    "sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(sentencizer)\n",
    "tokenizer = nlp.create_pipe(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the dataset in 7.33 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "dataset = pickle.load( open( params['pickleFile'], \"rb\" ))\n",
    "duration = time.clock() - start\n",
    "print(\"Loaded the dataset in\", round(duration,2), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 63001 amazon items.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\",len(dataset), \"amazon items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Glove Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading files.. Done.\n"
     ]
    }
   ],
   "source": [
    "def loadGlove(glove_path, dim=50):\n",
    "    acceptedDimensions = [50, 100, 200, 300]\n",
    "    if dim not in acceptedDimensions:\n",
    "        print(\"You didn't choose a right dimension.\")\n",
    "        print(\"Try one of these:\", acceptedDimensions)\n",
    "        return None\n",
    "    pickleWordFile = f'{glove_path}/6B.'+str(dim)+'_words.pkl'\n",
    "    pickleIdFile   = f'{glove_path}/6B.'+str(dim)+'_idx.pkl'\n",
    "    pickleDatFile  = f'{glove_path}/glove.6B.'+str(dim)+'.dat'\n",
    "    pickleDataset  = f'{glove_path}/glove.6B.'+str(dim)+'d.txt'\n",
    "    \n",
    "    if os.path.isfile(pickleWordFile):\n",
    "        # check if we've made the outputs before\n",
    "        print(\"Preloading files..\", end=\" \")\n",
    "        vectors = bcolz.open(pickleDatFile)[:]\n",
    "        words = pickle.load(open(pickleWordFile, 'rb'))\n",
    "        word2idx = pickle.load(open(pickleIdFile, 'rb'))\n",
    "        glove = {w: vectors[word2idx[w]] for w in words}\n",
    "        print(\"Done.\")\n",
    "        return glove\n",
    "    else:\n",
    "        print(\"Doesn't work.\", end=\" \")\n",
    "\n",
    "glove = loadGlove(params['glovePath'], dim=params['gloveDimension'])\n",
    "gloveWords = glove.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Vocabulary Size: 400000\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove Vocabulary Size:\",len(gloveWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(paragraph):\n",
    "    # split paragraph by full stops\n",
    "    paragraph = paragraph.lower()\n",
    "    paragraph = re.sub(\"([,!?()-+&£$.%*'])\", r' \\1 ', paragraph)\n",
    "    paragraph = re.sub('\\s{2,}', ' ', paragraph)\n",
    "    paragraph = paragraph.split(\" \")\n",
    "    # remove empty string\n",
    "    return paragraph\n",
    "    \n",
    "def discretise(value, word):\n",
    "    return word + \"_\" + str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleItem(itemID, dataset=dataset, printDebug=False):\n",
    "    \"\"\"\n",
    "    Filters words out based on whether they're in the GloVe dataset or not.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    reviews = []\n",
    "    for i in range(len(dataset[itemID])):\n",
    "        # initialise variables\n",
    "        entry = dataset[itemID][i]\n",
    "        reviewerID = entry['reviewerID']\n",
    "        \n",
    "        if len(entry['reviewText']) < 1:\n",
    "            continue\n",
    "\n",
    "        \"\"\"\n",
    "        Review Text Processing\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        # spacy method\n",
    "        sentences = [[str(i).lower() for i in tokenizer(str(sentence))] for sentence in nlp(entry['reviewText']).sents]\n",
    "        \n",
    "        # preprocess summary\n",
    "        summary = [str(i).lower() for i in tokenizer(entry['summary'])]\n",
    "        \n",
    "        # merge summary sequence and review sequences together into overall entries.\n",
    "#         if len(sentences) < 2:\n",
    "#             entries =  [[\"<sos>\", \"<summary>\"] + summary + [\"</summary>\"]] + [[\"<sos>\", \"<text>\"] + sentences[0] + [\"</text>\", \"<eor>\", \"<eos>\"]]\n",
    "#         else:\n",
    "#             subset = [[\"<sos>\", \"<text>\"] + x + [\"</text>\"] for x in sentences[:-1]]\n",
    "#             entries =  [[\"<sos>\", \"<summary>\"] + summary + [\"</summary>\"]] + subset + [[\"<sos>\", \"<text>\"] + sentences[-1] + [\"</text>\", \"<eor>\", \"<eos>\"]]\n",
    "        \n",
    "        entries = [summary] + sentences\n",
    "        entries = [x + [\"<eos>\"] for x in entries]\n",
    "  \n",
    "        # setup review parameters\n",
    "        rating   = [discretise(entry['overall'], \"rating\")]\n",
    "\n",
    "        # compute polarity\n",
    "        good, bad = entry['helpful'][0], entry['helpful'][1]\n",
    "        \n",
    "        try:\n",
    "            polarity = (good - bad) / (good + bad)\n",
    "        except ZeroDivisionError:\n",
    "            polarity = 0\n",
    "        polarity = np.tanh(polarity)\n",
    "        polarity = np.round(polarity, 1)\n",
    "        polarity = [discretise(polarity, \"polarity\")]\n",
    "\n",
    "        # create identity/conditioning entry\n",
    "        identifier = itemID.lower()\n",
    "        identity = [l for l in identifier] + rating + polarity\n",
    "\n",
    "        # add conditionining entry to each entry\n",
    "        formatted = [entry for entry in entries]\n",
    "\n",
    "        if printDebug:\n",
    "            print(\"ENTRY:\",dataset[itemID][i])\n",
    "            print(\"IDENTITY:\",identity)\n",
    "\n",
    "        for i in range(len(formatted)-1):\n",
    "            # add the conditioning variable to the input. the output value does not have the conditioning variable.\n",
    "            reviews.append([identity + formatted[i], formatted[i+1]])\n",
    "            if printDebug:\n",
    "                print(reviews[-1][0], \"->\", reviews[-1][1])\n",
    "        if printDebug:\n",
    "            break\n",
    "            \n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRY: {'reviewerID': 'AA8JH8LD2H4P9', 'asin': '7214047977', 'reviewerName': 'Claudia J. Frier', 'helpful': [3, 4], 'reviewText': 'This fits my 7\" kindle fire hd perfectly! I love it. It even has a slot for a stylus. The kindle is velcroed in so it\\'s nice and secure. Very glad I bought this!', 'overall': 5.0, 'summary': 'love it', 'unixReviewTime': 1354665600, 'reviewTime': '12 5, 2012'}\n",
      "IDENTITY: ['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', 'love', 'it', '<eos>'] -> ['this', 'fits', 'my', '7', '\"', 'kindle', 'fire', 'hd', 'perfectly', '!', '<eos>']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', 'this', 'fits', 'my', '7', '\"', 'kindle', 'fire', 'hd', 'perfectly', '!', '<eos>'] -> ['i', 'love', 'it', '.', '<eos>']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', 'i', 'love', 'it', '.', '<eos>'] -> ['it', 'even', 'has', 'a', 'slot', 'for', 'a', 'stylus', '.', '<eos>']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', 'it', 'even', 'has', 'a', 'slot', 'for', 'a', 'stylus', '.', '<eos>'] -> ['the', 'kindle', 'is', 'velcroed', 'in', 'so', 'it', \"'s\", 'nice', 'and', 'secure', '.', '<eos>']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', 'the', 'kindle', 'is', 'velcroed', 'in', 'so', 'it', \"'s\", 'nice', 'and', 'secure', '.', '<eos>'] -> ['very', 'glad', 'i', 'bought', 'this', '!', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "datasetKeys = list(dataset.keys())\n",
    "example_set = handleItem(datasetKeys[params['example_item_id']],printDebug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "identity = example_set[0][0][:example_set[0][0].index(\"<eos>\")]\n",
    "\n",
    "example_tag = {\"reference\":dataset[datasetKeys[params['example_item_id']]][0],\n",
    "               \"result\":example_set}\n",
    "# print(json.dumps(example_tag, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63001\n"
     ]
    }
   ],
   "source": [
    "print(len(datasetKeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processItems(func, args, n_processes = 7):\n",
    "    p = Pool(n_processes)\n",
    "    res_list = []\n",
    "    with tqdm(total = len(args)) as pbar:\n",
    "        for i, res in enumerate(p.imap_unordered(func, args)):\n",
    "            pbar.update()\n",
    "            res_list.append(res)\n",
    "    pbar.close()\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 29.95it/s]\n"
     ]
    }
   ],
   "source": [
    "reviews = processItems(handleItem,datasetKeys[::params['datasetReduction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Reviews:\n",
      "Training: 24 \t\tValidation: 7\n",
      "Sequences:\n",
      "Training: 1866 \tValidation: 2629\n"
     ]
    }
   ],
   "source": [
    "datasetSize = len(reviews)\n",
    "trainRatio = int(datasetSize * params['trainPortion'])\n",
    "\n",
    "train = reviews[:trainRatio]\n",
    "validation = reviews[trainRatio:]\n",
    "\n",
    "print(\"Num Reviews:\")\n",
    "print(\"Training:\", len(train), \"\\t\\tValidation:\",len(validation))\n",
    "\n",
    "# now we need to flatten train and validation.\n",
    "trainents = []\n",
    "for review in train:\n",
    "    trainents += [entry for entry in review]\n",
    "valents = []\n",
    "for review in validation:\n",
    "    valents += [entry for entry in review]\n",
    "    \n",
    "train = trainents\n",
    "validation = valents\n",
    "\n",
    "print(\"Sequences:\")\n",
    "print(\"Training:\",len(train),\"\\tValidation:\",len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b', '0', '0', '0', 'j', 'g', '1', 't', 'd', 'w', 'rating_5.0', 'polarity_0.0', 'great', 'card', '<eos>'], ['very', 'reliable', 'card', 'with', 'extra', 'features', '.', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "# get the number of itemIDs\n",
    "for row in train:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ID's of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the throughput of the model, we should reduce the embedding size. Here we'll look at all the words and keep track ones that exist. We'll make a reduced word2id based on this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcounts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting Reviews..\n",
      "We now have 1866 reviews.\n"
     ]
    }
   ],
   "source": [
    "# here we reduce the size of the dataset so we can debug our model.\n",
    "print(\"Subsetting Reviews..\")\n",
    "print(\"We now have\", len(train), \"reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1866/1866 [00:00<00:00, 33259.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# get word frequency for words in training data\n",
    "for row in tqdm(train):\n",
    "    for sequences in row:\n",
    "        for word in sequences:\n",
    "            word = str(word)\n",
    "            # setup container if word does not exist\n",
    "            if word not in wordcounts:\n",
    "                wordcounts[word] = 0\n",
    "            # increment\n",
    "            wordcounts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words that are not in the glove dataset\n",
    "knowns   = [word for word in wordcounts if word in glove]\n",
    "unknowns = [word for word in wordcounts if word not in glove]\n",
    "# sort words by their frequency\n",
    "wordOrder = list(sorted(knowns, key=lambda x: wordcounts[x], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689 420\n"
     ]
    }
   ],
   "source": [
    "print(len(knowns), len(unknowns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold number of tokens based on the vocabulary limit.\n",
    "wordOrder = wordOrder[:params['vocabularyLimit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store glove vectors for each token\n",
    "weights = [glove[word] for word in wordOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectors for rating and polarity\n",
    "for word in unknowns:\n",
    "    if (\"rating\" in word) or (\"polarity\" in word):\n",
    "        try:\n",
    "            part = word.split(\"_\")\n",
    "            if part[1] == \"-0.0\":\n",
    "                part[1] = \"0.0\"\n",
    "            weight = glove[part[0]] + glove[part[1]]\n",
    "            wordOrder.append(word)\n",
    "            weights.append(weight)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries for constant time referencing\n",
    "id2word = {idx: w for (idx, w) in enumerate(wordOrder)}\n",
    "word2id = {w: idx for (idx, w) in enumerate(wordOrder)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = len(word2id)\n",
    "\n",
    "# add <sos> (start of sequence)\n",
    "weights.append(glove['sos'])\n",
    "word2id['<sos>'] = lim\n",
    "id2word[lim] = ['<sos>']\n",
    "lim += 1\n",
    "\n",
    "# add <eos> (end of sequence)\n",
    "weights.append(glove['eos'])\n",
    "word2id['<eos>'] = lim\n",
    "id2word[lim] = '<eos>'\n",
    "lim += 1\n",
    "\n",
    "\n",
    "gloveDimension = params['gloveDimension']\n",
    "\n",
    "sorWeight = np.random.normal(0,0.5,gloveDimension)\n",
    "weights.append(sorWeight)\n",
    "word2id['<summary>'] = lim\n",
    "id2word[lim] = '<summary>'\n",
    "lim += 1\n",
    "\n",
    "sorWeight = np.random.normal(0,0.5,gloveDimension)\n",
    "weights.append(sorWeight)\n",
    "word2id['</summary>'] = lim\n",
    "id2word[lim] = '</summary>'\n",
    "lim += 1\n",
    "\n",
    "sorWeight = np.random.normal(0,0.5,gloveDimension)\n",
    "weights.append(sorWeight)\n",
    "word2id['<text>'] = lim\n",
    "id2word[lim] = '<text>'\n",
    "lim += 1\n",
    "\n",
    "sorWeight = np.random.normal(0,0.5,gloveDimension)\n",
    "weights.append(sorWeight)\n",
    "word2id['</text>'] = lim\n",
    "id2word[lim] = '</text>'\n",
    "lim += 1\n",
    "\n",
    "\n",
    "# add <unk> (unknown token)\n",
    "weights.append(glove['unk'])\n",
    "word2id['<unk>'] = lim\n",
    "id2word[lim] = '<unk>'\n",
    "\n",
    "# add <pad> \n",
    "id2word[len(word2id)] = \"<pad>\"\n",
    "word2id[\"<pad>\"] = len(word2id)\n",
    "weights.append(np.random.normal(0,0,gloveDimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions that incorporate dictionary search\n",
    "# and returns <unk> token upon failure\n",
    "def wordToID(word,corp=word2id):\n",
    "    if word in corp:\n",
    "        return corp[word]\n",
    "    return corp['<unk>']\n",
    "\n",
    "def IDToWord(id,corp=id2word, ref=word2id):\n",
    "    if id in corp:\n",
    "        return corp[id]\n",
    "    return corp[ref['<unk>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1866/1866 [00:00<00:00, 73970.26it/s]\n",
      "100%|██████████| 2629/2629 [00:00<00:00, 105876.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert words to their id's in the review.\n",
    "def entriesToWordIDs(group):\n",
    "    return [[[wordToID(word) for word in seq] for seq in row] for row in tqdm(group)]\n",
    "    \n",
    "train = entriesToWordIDs(train)\n",
    "validation = entriesToWordIDs(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest sequence in our dataset is 263 tokens long.\n"
     ]
    }
   ],
   "source": [
    "sizes = {}\n",
    "for i in range(len(train)):\n",
    "    row = train[i]\n",
    "    for seq in row:\n",
    "        length = len(seq)\n",
    "        if length not in sizes:\n",
    "            sizes[length] = []\n",
    "        sizes[length].append(i)\n",
    "\n",
    "seqlengths = list(sorted(sizes.keys(), key=lambda x: len(sizes[x]), reverse=True))\n",
    "print(\"The longest sequence in our dataset is\",max(seqlengths),\"tokens long.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i wonder what apple has it in store for the powerbook g5 next year . <eos>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the longest sequence.\n",
    "\" \".join([IDToWord(x) for x in train[sizes[max(seqlengths)][0]][1][1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for charting purposes\n",
    "for i in range(1709):\n",
    "    if i not in sizes:\n",
    "        sizes[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of sequence lengths\n",
    "ents = [x for x in range(0,80)]\n",
    "bins = [len(sizes[x]) for x in ents]\n",
    "plt.bar(ents,bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff sequence length: 39\n"
     ]
    }
   ],
   "source": [
    "print(\"Cutoff sequence length:\", params['cutoff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1866/1866 [00:00<00:00, 2071617.59it/s]\n",
      "100%|██████████| 2629/2629 [00:00<00:00, 2387792.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: 1866 2629\n",
      "AFTER: 1477 1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def trimSeq(group, cutoff):\n",
    "    good = []\n",
    "    for i in tqdm(range(len(group))):\n",
    "        row = group[i]\n",
    "        if len(row[0]) <= cutoff and len(row[1]) <= cutoff:\n",
    "            good.append(i) \n",
    "    group = [group[x] for x in good]\n",
    "    return group\n",
    "\n",
    "#     return [[seq[:cutoff] for seq in row] for row in tqdm(group)]\n",
    "\n",
    "print(\"BEFORE:\", len(train), len(validation))\n",
    "train = trimSeq(train, params['cutoff'])\n",
    "validation = trimSeq(validation, params['cutoff'])\n",
    "print(\"AFTER:\", len(train), len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create container ready for use in dataset\n",
    "# we do not add padding here as we want to reduce storage size!\n",
    "container = {\n",
    "    'id2word' : id2word,\n",
    "    'word2id' : word2id,\n",
    "    'train' : train,\n",
    "    'validation': validation,\n",
    "    'weights' : np.matrix(weights),\n",
    "    'cutoff' : params['cutoff']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "if params['saveDataset']:\n",
    "    # save the dataset to a pickle file.\n",
    "    output = open(params['datasetFile'], 'wb')\n",
    "    pickle.dump(container, output)\n",
    "    output.close()\n",
    "\n",
    "    # save dataset preprocessing parameters\n",
    "    params['example_filtering'] = example_tag\n",
    "    params['handleItem'] = inspect.getsource(handleItem)\n",
    "    param_jsonpath = 'dataset_parameters.json'\n",
    "    with open(param_jsonpath, 'w') as outfile:\n",
    "        json.dump(params, outfile)\n",
    "\n",
    "    print(\"Saved!\", convert_bytes(os.stat(params['datasetFile']).st_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sequence lengths for train and validation data\n",
    "trainx = [x[0] for x in train]\n",
    "trainy = [x[1] for x in train]\n",
    "valx   = [x[0] for x in validation]\n",
    "valy   = [x[1] for x in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b', '0', '0', '0', 'j', 'g', '1', 't', 'd', 'w', 'rating_5.0', 'polarity_0.0', 'very', 'reliable', 'card', 'with', 'extra', 'features', '.', '<eos>'], ['i', 'can', 'find', ' ', 'ethernet', 'cards', 'in', 'local', 'stores', 'anymore', '.', '<eos>']]\n",
      "---\n",
      "['b' '0' '0' '0' 'j' 'g' '1' 't' 'd' 'w' 'rating_5.0' 'polarity_0.0'\n",
      " 'great' 'card' '<eos>'] ['very' 'reliable' 'card' 'with' 'extra' 'features' '.' '<eos>']\n",
      "['b' '0' '0' '0' 'j' 'g' '1' 't' 'd' 'w' 'rating_5.0' 'polarity_0.0'\n",
      " 'very' 'reliable' 'card' 'with' 'extra' 'features' '.' '<eos>'] ['i' 'can' 'find' '<unk>' 'ethernet' 'cards' 'in' 'local' 'stores'\n",
      " 'anymore' '.' '<eos>']\n",
      "['b' '0' '0' '0' 'j' 'g' '1' 't' 'd' 'w' 'rating_5.0' 'polarity_0.0' 'i'\n",
      " 'can' 'find' '<unk>' 'ethernet' 'cards' 'in' 'local' 'stores' 'anymore'\n",
      " '.' '<eos>'] ['i' 'was' 'kind' 'of' 'worried' 'that' 'this' 'card' 'maybe' 'too' 'weak'\n",
      " 'for' 'the' 'project' 'i' 'was' 'working' 'on' '.' '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print(reviews[0][1])\n",
    "print(\"---\")\n",
    "for i in range(0,3):\n",
    "    xtext = np.array([id2word[x] for x in trainx[i]])\n",
    "    ytext = np.array([id2word[x] for x in trainy[i]])\n",
    "    print(xtext, ytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vad_utils import batchData\n",
    "\n",
    "device = \"cpu\"\n",
    "batchsize = 32\n",
    "trainx_p = batchData(trainx, word2id['<pad>'], device, batchsize, params['cutoff'])\n",
    "trainy_p = batchData(trainy, word2id['<pad>'], device, batchsize, params['cutoff'])\n",
    "trainy_r = batchData(trainy, word2id['<pad>'], device, batchsize, params['cutoff'], backwards=True)\n",
    "valx_p = batchData(valx, word2id['<pad>'], device, batchsize, params['cutoff'])\n",
    "valy_p = batchData(valy, word2id['<pad>'], device, batchsize, params['cutoff'])\n",
    "\n",
    "train_p = (trainx_p, trainy_p)\n",
    "val_p = (valx_p, valy_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: b 0 0 0 y m s y d y rating_3.0 polarity_0.0 however if i connect my headphone with my mobile , i can easily go to any part of my apartment without an hiccups in music . <eos>\n",
      "Y: ... not much to say here ..... i installed it .... closed up the case ... and it has worked flawlessly ever <unk> ... great <unk> for the money <unk> <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> <unk> money the for <unk> great ... <unk> ever flawlessly worked has it and ... case the up closed .... it installed i ..... here say to much not ... <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_4.0 polarity_0.0 <unk> one doa , promptly replaced by amazon - amazing service , replaced with next day delivery even before returned unit got to ups . <eos> <pad>\n",
      "Y: <unk> cheap capacitors - these boards have only five of these unreliable parts versus others that have seven or more , which i take to be a good thing . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . thing good a be to take i which , more or seven have that others versus parts unreliable these of five only have boards these - capacitors cheap <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 did not even know asus made ethernet cards but they had a good rep with me and this one was cheap . <eos> <pad> <pad> <pad> <pad>\n",
      "Y: good - it serves its purpose , once you connect it with your computer and switch on your bluetooth headphone , it will connect to it within seconds . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . seconds within it to connect will it , headphone bluetooth your on switch and computer your with it connect you once , purpose its serves it - good <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 plug and play , had no issues with xp sp4 . worked like a charm . low profile ! <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: so beware , bluetooth coverage of this adapter is very low , you can just move in the same room where it is connected to pc . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . pc to connected is it where room same the in move just can you , low very is adapter this of coverage bluetooth , beware so <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_4.0 polarity_0.0 <unk> wo n't last forever but inexpensive and the ones that work at all do so as advertised . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: however if i connect my headphone with my mobile , i can easily go to any part of my apartment without an hiccups in music . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . music in hiccups an without apartment my of part any to go easily can i , mobile my with headphone my connect i if however <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 i was kind of worried that this card maybe too weak for the project i was working on . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: <unk> one doa , promptly replaced by amazon - amazing service , replaced with next day delivery even before returned unit got to ups . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . ups to got unit returned before even delivery day next with replaced , service amazing - amazon by replaced promptly , doa one <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 y m s y d y rating_3.0 polarity_0.0 although it claims to be of bluetooth class 1 , its range of bluetooth is very limited . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: did not even know asus made ethernet cards but they had a good rep with me and this one was cheap . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . cheap was one this and me with rep good a had they but cards ethernet made asus know even not did <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 y m s y d y rating_3.0 polarity_0.0 you can not even go from one room to other room while listening to music . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: i was kind of worried that this card maybe too weak for the project i was working on . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . on working was i project the for weak too maybe card this that worried of kind was i <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 y m s y d y rating_3.0 polarity_0.0 do nt buy if you are using computer with wifi internet connection . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: you can not even go from one room to other room while listening to music . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . music to listening while room other to room one from go even not can you <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 <unk> this card works well , have not had any issues since . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: i simply dropped it in , and xp sp4 picked it up without hesitation . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . hesitation without up it picked sp4 xp and , in it dropped simply i <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 y m s y d y rating_3.0 polarity_0.0 i am using a my laptop with wifi based internet connection . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: <unk> this card works well , have not had any issues since . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . since issues any had not have , well works card this <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 needed this to replace an aging card in an older machine . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: i 've had one of these for a couple of years . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . years of couple a for these of one had 've i <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 i can find <unk> ethernet cards in local stores anymore . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: i am using a my laptop with wifi based internet connection . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . connection internet based wifi with laptop my a using am i <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 it was an easy install and it works great . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: needed this to replace an aging card in an older machine . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . machine older an in card aging an replace to this needed <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 y m s y d y rating_3.0 polarity_0.0 i purchased this adapter with motorola <unk> headphone . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: however , it has been fulfilling its duties without any glitches <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> glitches any without duties its fulfilling been has it , however <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 got this to replace nic in untangle server . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: i can find <unk> ethernet cards in local stores anymore . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . anymore stores local in cards ethernet <unk> find can i <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 throughput is as expected and price is right . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: <unk> now have <unk> speed running on my pc ! <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> ! pc my on running speed <unk> have now <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 <unk> no problems getting <unk> to recognize it . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: it was an easy install and it works great . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . great works it and install easy an was it <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 this card installed easily and worked immediately . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: i purchased this adapter with motorola <unk> headphone . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . headphone <unk> motorola with adapter this purchased i <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_4.0 polarity_0.0 a commodity product but it works well . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: got this to replace nic in untangle server . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . server untangle in nic replace to this got <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 used in a firewall appliance pc . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: no comment on life span at this time . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . time this at span life on comment no <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 nice upgrade for an old pc . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: throughput is as expected and price is right . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . right is price and expected as is throughput <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_4.0 polarity_0.0 <unk> these are a commodity item . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: <unk> no problems getting <unk> to recognize it . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . it recognize to <unk> getting problems no <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 very reliable card with extra features . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: this card installed easily and worked immediately . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . immediately worked and easily installed card this <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 y m s y d y rating_5.0 polarity_0.0 works great with many different devices <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: used in a firewall appliance pc . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . pc appliance firewall a in used <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 this worked like a charm . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: <unk> these are a commodity item . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . item commodity a are these <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 works in untangle server <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: very reliable card with extra features . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . features extra with card reliable very <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 asus ethernet card <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: this worked like a charm . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . charm a like worked this <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_4.0 polarity_0.0 ordered two . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: <unk> def worth the time . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . time the worth def <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 asus ethernet card <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: <unk> realtek <unk> chip . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . chip <unk> realtek <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 nice product <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: highly recommend it . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . it recommend highly <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "X: b 0 0 0 j g 1 t d w rating_5.0 polarity_0.0 great card <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Y: ordered two . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "R: <eos> . two ordered <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "x_row = trainx_p[0][0]\n",
    "y_row = trainy_p[0][0]\n",
    "ybrow = trainy_r[0][0]\n",
    "\n",
    "# print(x_row)\n",
    "\n",
    "\n",
    "# entries = [torch.argmax(entry, dim=1) for entry in outputs]\n",
    "text_x  = np.array([[id2word[x.item()] for x in y] for y in x_row])\n",
    "text_y  = np.array([[id2word[x.item()] for x in y] for y in y_row])\n",
    "text_r  = np.array([[id2word[x.item()] for x in y] for y in ybrow])\n",
    "for i in range(batchsize):\n",
    "    print(\"X:\",\" \".join(text_x[i].tolist()))\n",
    "    print(\"Y:\",\" \".join(text_y[i].tolist()))\n",
    "    print(\"R:\",\" \".join(text_r[i].tolist()))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3710, 50)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.matrix(weights)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.6320, grad_fn=<MeanBackward1>)\n",
      "tensor(-9.9381, grad_fn=<MeanBackward1>)\n",
      "tensor(-9.2458, grad_fn=<MeanBackward1>)\n",
      "tensor(-8.5473, grad_fn=<MeanBackward1>)\n",
      "tensor(-7.8437, grad_fn=<MeanBackward1>)\n",
      "tensor(-7.1514, grad_fn=<MeanBackward1>)\n",
      "tensor(-6.4831, grad_fn=<MeanBackward1>)\n",
      "tensor(-5.8103, grad_fn=<MeanBackward1>)\n",
      "tensor(-5.1587, grad_fn=<MeanBackward1>)\n",
      "tensor(-4.5477, grad_fn=<MeanBackward1>)\n",
      "tensor(-4.0300, grad_fn=<MeanBackward1>)\n",
      "tensor(-3.5736, grad_fn=<MeanBackward1>)\n",
      "tensor(-3.1263, grad_fn=<MeanBackward1>)\n",
      "tensor(-2.6906, grad_fn=<MeanBackward1>)\n",
      "tensor(-2.2979, grad_fn=<MeanBackward1>)\n",
      "tensor(-1.9264, grad_fn=<MeanBackward1>)\n",
      "tensor(-1.6036, grad_fn=<MeanBackward1>)\n",
      "tensor(-1.3219, grad_fn=<MeanBackward1>)\n",
      "tensor(-1.0798, grad_fn=<MeanBackward1>)\n",
      "tensor(-0.8852, grad_fn=<MeanBackward1>)\n",
      "tensor(-0.7144, grad_fn=<MeanBackward1>)\n",
      "tensor(-0.5616, grad_fn=<MeanBackward1>)\n",
      "tensor(-0.4098, grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2815, grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1969, grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1300, grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0640, grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0206, grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n",
      "tensor(0., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# cbow \n",
    "from vad import CBOW\n",
    "from torch import optim\n",
    "latent_size = 200\n",
    "cbow = CBOW(weights.shape[0], latent_size).to(device)\n",
    "z = Variable(torch.tensor(np.random.normal(0,0.5,(batchsize, latent_size)), dtype=torch.float))\n",
    "cel = nn.CrossEntropyLoss()\n",
    "nll = nn.NLLLoss()\n",
    "sig =nn.Sigmoid()\n",
    "opt = optim.Adam(cbow.parameters(),   lr=0.0001)\n",
    "\n",
    "asdf = [cd for cd in range(len(train_p[0]))]\n",
    "epoch_losses = []\n",
    "for epoch in tqdm(range(0,10)):\n",
    "    opt.zero_grad()\n",
    "    losses = 0\n",
    "    random.shuffle(asdf)\n",
    "    for batch in asdf:\n",
    "        # load x, y from batch\n",
    "        entry_x, entry_y = train_p[0][batch], train_p[1][batch]\n",
    "        # sepeate data from sentence lengths\n",
    "        y_outs, y_seqs = entry_y\n",
    "        # get y_length\n",
    "        y_len, num_classes, batch_size = len(y_outs[0]), weights.shape[0], y_outs.shape[0]\n",
    "        # iterate through the words in y\n",
    "        loss = 0\n",
    "        for w in range(y_len):\n",
    "            try:\n",
    "                # get indexes of future words\n",
    "                labels = y_outs[:,w:]\n",
    "                mask = (labels != word2id['<pad>']).float()\n",
    "                z = torch.zeros(z.shape)\n",
    "                # compute est bow\n",
    "                bow_guess = -cbow(z)\n",
    "                bow_guess = bow_guess.gather(1, labels)\n",
    "                \n",
    "                \n",
    "                \n",
    "                bow_guess = bow_guess * mask\n",
    "                bow_loss = torch.sum(bow_guess, 1)\n",
    "                avg_bow_loss = torch.mean(bow_loss)\n",
    "                print(avg_bow_loss)\n",
    "                loss += avg_bow_loss\n",
    "            except:\n",
    "                pass\n",
    "        break\n",
    "    break\n",
    "#         if loss != 0:\n",
    "#             loss = loss/y_len\n",
    "# #             print(loss.item())\n",
    "#             loss.backward()\n",
    "#             opt.step()\n",
    "#         losses += loss\n",
    "#     epoch_losses.append((losses/len(train_p[0])).detach().item())\n",
    "#     print(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbow \n",
    "\n",
    "cel = nn.CrossEntropyLoss()\n",
    "nll = nn.NLLLoss()\n",
    "# sig =nn.Sigmoid()\n",
    "\n",
    "for batch in range(len(train_p[0])):\n",
    "    # load x, y from batch\n",
    "    entry_x, entry_y = train_p[0][batch], train_p[1][batch]\n",
    "    \n",
    "    # sepeate data from sentence lengths\n",
    "    y_outs, y_seqs = entry_y\n",
    "    \n",
    "    # get y_length\n",
    "    y_len, num_classes, batch_size = len(y_outs[0]), weights.shape[0], y_outs.shape[0]\n",
    "    \n",
    "    # iterate through the words in y\n",
    "    for w in range(y_len):\n",
    "        # get indexes of future words\n",
    "        labels = y_outs[:,w:]\n",
    "\n",
    "        # create onehot output\n",
    "        actual_cbow = torch.FloatTensor(batch_size, num_classes).zero_()\n",
    "        actual_cbow.scatter_(1, y_outs[:,w:], 1)\n",
    "        \n",
    "        # ones for non-zero, zero for one-hot\n",
    "        ref_anti_cbow = torch.ones(batch_size, num_classes)\n",
    "        ref_anti_cbow.scatter_(1, y_outs[:,w:], 0)\n",
    "        \n",
    "        # generate some random matrix of the same shape\n",
    "        guess = torch.rand(batch_size, num_classes) * 2\n",
    "        guess = -F.log_softmax(sig(guess), dim=1)\n",
    "        \n",
    "#         print(\"BUG:\",bug)\n",
    "        group_loss = guess * ref_anti_cbow\n",
    "        \n",
    "        overall_loss = torch.sum(group_loss, dim=1)\n",
    "        overall_loss = torch.mean(overall_loss)\n",
    "#         print(\"OVL\", overall_loss)\n",
    "        \n",
    "#         rand = torch.rand(batch_size, num_classes)\n",
    "        \n",
    "#         label = y_outs[:, w]\n",
    "#         y_onehot = torch.FloatTensor(batch_size, num_classes).zero_()\n",
    "#         label = label.unsqueeze(1)\n",
    "#         y_onehot.scatter_(1,label,1)\n",
    "        \n",
    "#         print(y_onehot)\n",
    "        \n",
    "#         print(y_onehot, label.reshape(-1))\n",
    "        \n",
    "#         lossfunctions = [\n",
    "#             nn.BCEWithLogitsLoss(), \n",
    "#             F.cross_entropy,\n",
    "#             cel,\n",
    "#             nll\n",
    "#         ]\n",
    "        \n",
    "#         for losses in lossfunctions:\n",
    "#             pred = -y_onehot\n",
    "#             act  = label.reshape(-1)\n",
    "#             try:\n",
    "#                 print(losses, losses(y_onehot,act))\n",
    "#             except:\n",
    "#                 print(\"HUH\")\n",
    "#                 print(losses, losses(y_onehot,y_onehot))\n",
    "#         break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = torch.tensor([[0, 1, 0],\n",
    "                       [1, 0, 0],\n",
    "                       [0, 0, 1]]).float()\n",
    "# you would have to get the corresponding indices by:\n",
    "\n",
    "labels = onehot.argmax(1)\n",
    "print(labels)\n",
    "# > tensor([1, 0, 2])\n",
    "# Now you can use this target tensor for your criterion.\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "x = torch.randn(3, 3, requires_grad=True)\n",
    "\n",
    "loss = criterion(x, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_1, mu_2 = np.random.normal(0,1,[20,20]), np.random.normal(0,1,[20,20])\n",
    "var_1, var_2 =  np.random.normal(0,1,[20,20]), np.random.normal(0,1,[20,20])\n",
    "\n",
    "mu_1 = torch.tensor(mu_1)\n",
    "mu_2 = torch.tensor(mu_2)\n",
    "var_1 = torch.tensor(var_1)\n",
    "var_2 = torch.tensor(var_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def kl_og(mu_1, mu_2, var_1, var_2):\n",
    "    left = (var_1 - var_2)\n",
    "    middle = torch.div(torch.pow(mu_2 - mu_1, 2), torch.exp(var_2)) \n",
    "    right = torch.div(torch.exp(var_1), torch.exp(var_2))\n",
    "    kld = -0.5 * torch.sum(1 + left - middle - right, 1)\n",
    "    return kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_og(mu_1, mu_2, var_1, var_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(mu_1, mu_2, var_1, var_2):\n",
    "    left = torch.log(torch.sum(var_2)/torch.sum(var_1))\n",
    "    print(\"FAM\",torch.sum(var_2)/torch.sum(var_1))\n",
    "    middle =  - 1 + torch.trace(torch.mm(var_2.inverse(), var_1))\n",
    "    right = (mu_2 - mu_1).transpose(0,1).mm(var_2.inverse()).mm(mu_2 - mu_1)\n",
    "    kl = 0.5 * (left + middle + right)\n",
    "    print(left)\n",
    "    print(middle)\n",
    "    print(right)\n",
    "    \n",
    "kl(mu_1, mu_2, var_1, var_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
